{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(save_name='ResNet50.hdh5', image_shape=(224, 224, 3)):\n",
    "    import os\n",
    "    new_model = not os.path.exists(save_name)\n",
    "    if new_model:\n",
    "        from keras.applications.resnet50 import ResNet50\n",
    "        model = ResNet50(\n",
    "            include_top=False, weights='imagenet',\n",
    "            input_tensor=None, input_shape=image_shape, pooling='max'\n",
    "        )\n",
    "        model.save(save_name)\n",
    "    else:\n",
    "        from keras.models import load_model\n",
    "        model = load_model(save_name)\n",
    "    return model, new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/keras/models.py:245: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "initial_model, new_model = get_model()\n",
    "if new_model:\n",
    "    print('new model')\n",
    "else:\n",
    "    print('old model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(image_shape=(224, 224, 3)):\n",
    "    from skimage.transform import resize\n",
    "    from skimage.io import imread\n",
    "    import os\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open('public_data/00_input/train/gt.csv') as navigate_file:\n",
    "        for i, line in enumerate(navigate_file):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            image_name, label = line.split(',')                \n",
    "            images.append(resize(\n",
    "                imread(os.path.join(\n",
    "                    'public_data/00_input/train/images/',\n",
    "                    image_name\n",
    "                )),\n",
    "                image_shape,\n",
    "                mode='reflect'\n",
    "            ))\n",
    "            labels.append(int(label))\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(set(y))\n",
    "y = np.eye(num_classes)[y]\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularization_lambda = 0.0005\n",
    "\n",
    "last = initial_model.output\n",
    "\n",
    "prediction = Dense(\n",
    "    num_classes, activation='softmax',\n",
    "    kernel_regularizer=regularizers.l2(regularization_lambda),\n",
    "    bias_regularizer=regularizers.l2(regularization_lambda)\n",
    ")(last)\n",
    "\n",
    "model = Model(initial_model.input, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Nadam(lr=0.00005),\n",
    "    metrics=['categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "109/109 [==============================] - 85s - loss: 3.1477 - categorical_accuracy: 0.2374 - val_loss: 4.2747 - val_categorical_accuracy: 0.0160\n",
      "Epoch 2/300\n",
      "109/109 [==============================] - 76s - loss: 1.3168 - categorical_accuracy: 0.6996 - val_loss: 4.2211 - val_categorical_accuracy: 0.0213\n",
      "Epoch 3/300\n",
      "109/109 [==============================] - 76s - loss: 0.7486 - categorical_accuracy: 0.8358 - val_loss: 4.1156 - val_categorical_accuracy: 0.0173\n",
      "Epoch 4/300\n",
      "109/109 [==============================] - 76s - loss: 0.4573 - categorical_accuracy: 0.9249 - val_loss: 4.0102 - val_categorical_accuracy: 0.0320\n",
      "Epoch 5/300\n",
      "109/109 [==============================] - 76s - loss: 0.3214 - categorical_accuracy: 0.9438 - val_loss: 3.8108 - val_categorical_accuracy: 0.0733\n",
      "Epoch 6/300\n",
      "109/109 [==============================] - 76s - loss: 0.2359 - categorical_accuracy: 0.9622 - val_loss: 3.3903 - val_categorical_accuracy: 0.1667\n",
      "Epoch 7/300\n",
      "109/109 [==============================] - 76s - loss: 0.1818 - categorical_accuracy: 0.9776 - val_loss: 2.7738 - val_categorical_accuracy: 0.2853\n",
      "Epoch 8/300\n",
      "109/109 [==============================] - 76s - loss: 0.1357 - categorical_accuracy: 0.9937 - val_loss: 1.9624 - val_categorical_accuracy: 0.4707\n",
      "Epoch 9/300\n",
      "109/109 [==============================] - 76s - loss: 0.1172 - categorical_accuracy: 0.9880 - val_loss: 1.4820 - val_categorical_accuracy: 0.5987\n",
      "Epoch 10/300\n",
      "109/109 [==============================] - 76s - loss: 0.1105 - categorical_accuracy: 0.9943 - val_loss: 1.0926 - val_categorical_accuracy: 0.7027\n",
      "Epoch 11/300\n",
      "109/109 [==============================] - 76s - loss: 0.1081 - categorical_accuracy: 0.9880 - val_loss: 1.0790 - val_categorical_accuracy: 0.7093\n",
      "Epoch 12/300\n",
      "109/109 [==============================] - 76s - loss: 0.1039 - categorical_accuracy: 0.9927 - val_loss: 1.0615 - val_categorical_accuracy: 0.7067\n",
      "Epoch 13/300\n",
      "109/109 [==============================] - 76s - loss: 0.0898 - categorical_accuracy: 0.9943 - val_loss: 1.0780 - val_categorical_accuracy: 0.7053\n",
      "Epoch 14/300\n",
      "109/109 [==============================] - 76s - loss: 0.0805 - categorical_accuracy: 0.9989 - val_loss: 1.0187 - val_categorical_accuracy: 0.7360\n",
      "Epoch 15/300\n",
      "109/109 [==============================] - 76s - loss: 0.0883 - categorical_accuracy: 0.9948 - val_loss: 1.1373 - val_categorical_accuracy: 0.7147\n",
      "Epoch 16/300\n",
      "109/109 [==============================] - 76s - loss: 0.0851 - categorical_accuracy: 0.9948 - val_loss: 1.1572 - val_categorical_accuracy: 0.7240\n",
      "Epoch 17/300\n",
      "109/109 [==============================] - 76s - loss: 0.0735 - categorical_accuracy: 0.9971 - val_loss: 1.0547 - val_categorical_accuracy: 0.7320\n",
      "Epoch 18/300\n",
      "109/109 [==============================] - 76s - loss: 0.0702 - categorical_accuracy: 0.9977 - val_loss: 1.1613 - val_categorical_accuracy: 0.7213\n",
      "Epoch 19/300\n",
      "109/109 [==============================] - 76s - loss: 0.0669 - categorical_accuracy: 0.9989 - val_loss: 1.1250 - val_categorical_accuracy: 0.7400\n",
      "Epoch 20/300\n",
      "109/109 [==============================] - 76s - loss: 0.0928 - categorical_accuracy: 0.9903 - val_loss: 1.4787 - val_categorical_accuracy: 0.6733\n",
      "Epoch 21/300\n",
      "109/109 [==============================] - 76s - loss: 0.0982 - categorical_accuracy: 0.9862 - val_loss: 1.1825 - val_categorical_accuracy: 0.7213\n",
      "Epoch 22/300\n",
      "109/109 [==============================] - 76s - loss: 0.1044 - categorical_accuracy: 0.9908 - val_loss: 1.3044 - val_categorical_accuracy: 0.6973\n",
      "Epoch 23/300\n",
      "109/109 [==============================] - 76s - loss: 0.1020 - categorical_accuracy: 0.9885 - val_loss: 1.4730 - val_categorical_accuracy: 0.6680\n",
      "Epoch 24/300\n",
      "109/109 [==============================] - 76s - loss: 0.1059 - categorical_accuracy: 0.9817 - val_loss: 1.2431 - val_categorical_accuracy: 0.7133\n",
      "Epoch 25/300\n",
      "109/109 [==============================] - 76s - loss: 0.0860 - categorical_accuracy: 0.9925 - val_loss: 1.2073 - val_categorical_accuracy: 0.7200\n",
      "Epoch 26/300\n",
      "109/109 [==============================] - 76s - loss: 0.0964 - categorical_accuracy: 0.9895 - val_loss: 1.1945 - val_categorical_accuracy: 0.7267\n",
      "Epoch 27/300\n",
      "109/109 [==============================] - 76s - loss: 0.0759 - categorical_accuracy: 0.9971 - val_loss: 1.2549 - val_categorical_accuracy: 0.7213\n",
      "Epoch 28/300\n",
      "109/109 [==============================] - 76s - loss: 0.0847 - categorical_accuracy: 0.9914 - val_loss: 1.2128 - val_categorical_accuracy: 0.7293\n",
      "Epoch 29/300\n",
      "109/109 [==============================] - 76s - loss: 0.0821 - categorical_accuracy: 0.9943 - val_loss: 1.3524 - val_categorical_accuracy: 0.6987\n",
      "Epoch 30/300\n",
      "109/109 [==============================] - 76s - loss: 0.0737 - categorical_accuracy: 0.9954 - val_loss: 1.3274 - val_categorical_accuracy: 0.7027\n",
      "Epoch 31/300\n",
      "109/109 [==============================] - 76s - loss: 0.0811 - categorical_accuracy: 0.9925 - val_loss: 1.3658 - val_categorical_accuracy: 0.6920\n",
      "Epoch 32/300\n",
      "109/109 [==============================] - 76s - loss: 0.1022 - categorical_accuracy: 0.9880 - val_loss: 1.3626 - val_categorical_accuracy: 0.7027\n",
      "Epoch 33/300\n",
      "109/109 [==============================] - 76s - loss: 0.0741 - categorical_accuracy: 0.9960 - val_loss: 1.3168 - val_categorical_accuracy: 0.7200\n",
      "Epoch 34/300\n",
      "109/109 [==============================] - 76s - loss: 0.0704 - categorical_accuracy: 0.9948 - val_loss: 1.3405 - val_categorical_accuracy: 0.7227\n",
      "Epoch 35/300\n",
      "109/109 [==============================] - 76s - loss: 0.0652 - categorical_accuracy: 0.9983 - val_loss: 1.2991 - val_categorical_accuracy: 0.7240\n",
      "Epoch 36/300\n",
      "109/109 [==============================] - 76s - loss: 0.0700 - categorical_accuracy: 0.9943 - val_loss: 1.3573 - val_categorical_accuracy: 0.7040\n",
      "Epoch 37/300\n",
      "109/109 [==============================] - 76s - loss: 0.0672 - categorical_accuracy: 0.9939 - val_loss: 1.3367 - val_categorical_accuracy: 0.7107\n",
      "Epoch 38/300\n",
      "109/109 [==============================] - 76s - loss: 0.0706 - categorical_accuracy: 0.9945 - val_loss: 1.3164 - val_categorical_accuracy: 0.7133\n",
      "Epoch 39/300\n",
      "109/109 [==============================] - 76s - loss: 0.0647 - categorical_accuracy: 0.9960 - val_loss: 1.3591 - val_categorical_accuracy: 0.7133\n",
      "Epoch 40/300\n",
      "109/109 [==============================] - 76s - loss: 0.0732 - categorical_accuracy: 0.9937 - val_loss: 1.4754 - val_categorical_accuracy: 0.6920\n",
      "Epoch 41/300\n",
      "109/109 [==============================] - 76s - loss: 0.0704 - categorical_accuracy: 0.9937 - val_loss: 1.5279 - val_categorical_accuracy: 0.6733\n",
      "Epoch 42/300\n",
      "109/109 [==============================] - 76s - loss: 0.0766 - categorical_accuracy: 0.9943 - val_loss: 1.4993 - val_categorical_accuracy: 0.7000\n",
      "Epoch 43/300\n",
      "109/109 [==============================] - 76s - loss: 0.0824 - categorical_accuracy: 0.9937 - val_loss: 1.4993 - val_categorical_accuracy: 0.7053\n",
      "Epoch 44/300\n",
      "109/109 [==============================] - 76s - loss: 0.0624 - categorical_accuracy: 0.9977 - val_loss: 1.2749 - val_categorical_accuracy: 0.7280\n",
      "Epoch 45/300\n",
      "109/109 [==============================] - 76s - loss: 0.0825 - categorical_accuracy: 0.9931 - val_loss: 1.5755 - val_categorical_accuracy: 0.6880\n",
      "Epoch 46/300\n",
      "109/109 [==============================] - 76s - loss: 0.0695 - categorical_accuracy: 0.9943 - val_loss: 1.3351 - val_categorical_accuracy: 0.7187\n",
      "Epoch 47/300\n",
      "109/109 [==============================] - 76s - loss: 0.0655 - categorical_accuracy: 0.9948 - val_loss: 1.3631 - val_categorical_accuracy: 0.7133\n",
      "Epoch 48/300\n",
      "109/109 [==============================] - 76s - loss: 0.0699 - categorical_accuracy: 0.9925 - val_loss: 1.3084 - val_categorical_accuracy: 0.7067\n",
      "Epoch 49/300\n",
      "109/109 [==============================] - 76s - loss: 0.0559 - categorical_accuracy: 1.0000 - val_loss: 1.4295 - val_categorical_accuracy: 0.7120\n",
      "Epoch 50/300\n",
      "109/109 [==============================] - 76s - loss: 0.0793 - categorical_accuracy: 0.9927 - val_loss: 1.6090 - val_categorical_accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "109/109 [==============================] - 76s - loss: 0.0971 - categorical_accuracy: 0.9870 - val_loss: 1.6508 - val_categorical_accuracy: 0.6880\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/109 [============================>.] - ETA: 1s - loss: 0.1071 - categorical_accuracy: 0.9849"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit_generator(\n",
    "    data_generator.flow(train_x, train_y, batch_size=batch_size),\n",
    "    steps_per_epoch=int(len(train_y) / batch_size), epochs=300,\n",
    "    validation_data=(test_x, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('0.72_score_model.hdh5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
