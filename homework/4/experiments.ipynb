{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import threading\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from augmentation import ImageGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_data(path='public_data/00_input/train/'):\n",
    "    from skimage.io import imread\n",
    "    with open(path + 'gt.csv') as navigation_file:\n",
    "        splits = [line.split(',') for line in navigation_file]\n",
    "        points_number = int((len(splits[0]) - 1) / 2)\n",
    "        train_x = np.array([imread(path + 'images/' + split[0]) for split in splits[1:]])\n",
    "        train_y = np.array([[int(x) for x in split[1:]] for split in splits[1:]])\n",
    "        return train_x, train_y, points_number\n",
    "\n",
    "def get_colored_data(images, coordinates):\n",
    "    return (\n",
    "        np.array([image for image in images if len(np.shape(image)) == 3]),\n",
    "        np.array([answer for image, answer in zip(images, coordinates) if len(np.shape(image)) == 3])\n",
    "    )\n",
    "\n",
    "def get_resized_train_data(train_x, train_y, shape=(100, 100, 3)):\n",
    "    resized_x = np.array([resize(image, shape, mode='reflect') for image in train_x])\n",
    "    resized_y = np.array([[\n",
    "            int(coordinate * shape[i % 2] / np.shape(image)[i % 2])\n",
    "            for i, coordinate in enumerate(answer)\n",
    "        ] for image, answer in zip(train_x, train_y)\n",
    "    ])\n",
    "    return np.array(resized_x), np.array(resized_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_x, all_y, points_number = get_train_data()\n",
    "colored_x, colored_y = get_colored_data(all_x, all_y)\n",
    "resized_x, resized_y = get_resized_train_data(colored_x, colored_y)\n",
    "input_shape=np.shape(resized_x[0])\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    resized_x, resized_y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularization_lambda = 5e-6\n",
    "\n",
    "def add_Conv2D_relu(model, n_filter, filters_size, input_shape=None):\n",
    "    if input_shape is not None:\n",
    "        model.add(Conv2D(\n",
    "            n_filter, filters_size, padding='same',\n",
    "            kernel_regularizer=regularizers.l2(regularization_lambda),\n",
    "            activation='elu', input_shape=input_shape,\n",
    "        ))\n",
    "    else:\n",
    "        model.add(Conv2D(\n",
    "            n_filter, filters_size, padding='same',\n",
    "            kernel_regularizer=regularizers.l2(regularization_lambda),\n",
    "            activation='elu'\n",
    "        ))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "add_Conv2D_relu(model, 64, (3, 3), input_shape)\n",
    "add_Conv2D_relu(model, 64, (3, 3))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "add_Conv2D_relu(model, 128, (3, 3))\n",
    "add_Conv2D_relu(model, 128, (3, 3))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "add_Conv2D_relu(model, 256, (3, 3))\n",
    "add_Conv2D_relu(model, 256, (3, 3))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(512, activation='elu', kernel_regularizer=regularizers.l2(regularization_lambda)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='elu', kernel_regularizer=regularizers.l2(regularization_lambda)))\n",
    "\n",
    "model.add(Dense(points_number * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyClallback:\n",
    "    def __init__(self, model, directory):\n",
    "        self._model = model\n",
    "        self._directory = directory\n",
    "        self._counter = 0\n",
    "\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    def set_params(self, params):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs):\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, logs):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self._model.save(\n",
    "            self._directory + '/' + str(self._counter) +\n",
    "            '_mse:_' + str(logs['mean_squared_error']) +\n",
    "            '_val_mse:_' + str(logs['val_mean_squared_error']) +\n",
    "            '.npz'\n",
    "        )\n",
    "        self._counter += 1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "117/130 [==========================>...] - ETA: 4s - loss: 350.4289 - mean_squared_error: 350.4148"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(train_x, train_y, batch_size=32),\n",
    "                    steps_per_epoch=int(len(train_y) / 32), epochs=1000,\n",
    "                    callbacks=[MyClallback(model, 'aug_models')], validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "74.1453 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
